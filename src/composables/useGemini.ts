import { ref } from 'vue'
import { GoogleGenerativeAI } from '@google/generative-ai'
import type { AIGenerationType, LearningOutcome, MagicImportResult } from '@/types'

// Retry configuration
const MAX_RETRIES = 3
const INITIAL_DELAY = 1000 // 1 second

export function useGemini() {
  const loading = ref(false)
  const result = ref('')
  const error = ref('')
  const streamingText = ref('')
  const isStreaming = ref(false)
  const retryCount = ref(0)

  // Sleep function for retry delays
  const sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms))

  // Retry wrapper with exponential backoff
  const withRetry = async <T>(
    fn: () => Promise<T>,
    onRetry?: (attempt: number, delay: number) => void
  ): Promise<T> => {
    let lastError: Error | null = null

    for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
      try {
        retryCount.value = attempt
        return await fn()
      } catch (err) {
        lastError = err instanceof Error ? err : new Error(String(err))

        // Check if it's a retryable error (503, rate limit, etc.)
        const isRetryable = lastError.message.includes('503') ||
          lastError.message.includes('overloaded') ||
          lastError.message.includes('rate limit') ||
          lastError.message.includes('RESOURCE_EXHAUSTED')

        if (!isRetryable || attempt === MAX_RETRIES - 1) {
          throw lastError
        }

        const delay = INITIAL_DELAY * Math.pow(2, attempt)
        onRetry?.(attempt + 1, delay)
        await sleep(delay)
      }
    }

    throw lastError
  }

  // Validate API key
  const validateApiKey = async (apiKey: string): Promise<{ valid: boolean; error?: string }> => {
    try {
      const genAI = new GoogleGenerativeAI(apiKey)
      const model = genAI.getGenerativeModel({ model: 'gemini-3-flash-preview' })

      // Simple test request
      await model.generateContent('Test. Reply with OK.')

      return { valid: true }
    } catch (err) {
      const message = err instanceof Error ? err.message : 'Erreur inconnue'

      if (message.includes('API_KEY_INVALID') || message.includes('invalid')) {
        return { valid: false, error: 'Cl√© API invalide' }
      }
      if (message.includes('quota') || message.includes('QUOTA')) {
        return { valid: false, error: 'Quota API d√©pass√©' }
      }

      return { valid: false, error: message }
    }
  }

  // Generate content with streaming support
  const generateContent = async (
    apiKey: string,
    model: string,
    outcome: LearningOutcome,
    type: AIGenerationType,
    useStreaming = false,
    onRetryCallback?: (attempt: number, delay: number) => void
  ) => {
    console.log('üîß useGemini.generateContent called')
    console.log('Model:', model)
    console.log('Type:', type)
    console.log('Streaming:', useStreaming)

    loading.value = true
    error.value = ''
    result.value = ''
    streamingText.value = ''
    isStreaming.value = useStreaming

    try {
      const generateFn = async () => {
        console.log('üîë Initializing Gemini AI...')
        const genAI = new GoogleGenerativeAI(apiKey)
        const aiModel = genAI.getGenerativeModel({ model })
        console.log('‚úì Gemini AI initialized')

        let prompt = ''
        const context = `${outcome.description} (Niveau ${outcome.level})`

        switch (type) {
          case 'course':
            prompt = `Tu es un enseignant expert. Cr√©e un plan de cours structur√© pour : "${context}".

R√©ponds en markdown avec ce format :
## Introduction
[Pr√©sentation du sujet en 2-3 phrases]

## Concept 1 : [Titre]
[Explication d√©taill√©e]

## Concept 2 : [Titre]
[Explication d√©taill√©e]

## Concept 3 : [Titre]
[Explication d√©taill√©e]

## Exemple Pratique
[Cas concret d'application]

## Conclusion
[Synth√®se et perspectives]`
            break

          case 'td':
            prompt = `Tu es un enseignant expert. Cr√©e un exercice progressif de TD pour : "${context}".

R√©ponds en markdown avec ce format :
## Objectif
[Description de l'objectif p√©dagogique]

## Pr√©requis
[Liste des connaissances n√©cessaires]

## √âtape 1 : [Titre]
[Instructions et questions]

## √âtape 2 : [Titre]
[Instructions et questions]

## √âtape 3 : [Titre]
[Instructions et questions]

## Pour aller plus loin
[Suggestions d'approfondissement]`
            break

          case 'qcm':
            prompt = `Tu es un enseignant expert. Cr√©e un QCM de 5 questions pour √©valuer : "${context}".

R√©ponds en markdown avec ce format :
### Question 1
[√ânonc√© de la question]

a) [Choix A]
b) [Choix B]
c) [Choix C]
d) [Choix D]

**R√©ponse correcte :** [Lettre]
**Explication :** [Justification]

[R√©p√©ter pour les 5 questions]`
            break

          case 'practice':
            prompt = `Tu es un enseignant expert. Cr√©e une mise en situation professionnelle pour : "${context}".

R√©ponds en markdown avec ce format :
## Contexte Professionnel
[Description du contexte de travail]

## Situation
[Description d√©taill√©e de la situation]

## T√¢che √† R√©aliser
[Liste pr√©cise des actions attendues]

## Crit√®res de R√©ussite
[Comment √©valuer la r√©alisation]

## Ressources Disponibles
[Outils et documents √† disposition]`
            break
        }

        console.log('üìù Prompt generated, calling API...')

        if (useStreaming) {
          const response = await aiModel.generateContentStream(prompt)

          for await (const chunk of response.stream) {
            const text = chunk.text()
            streamingText.value += text
          }

          result.value = streamingText.value
        } else {
          const response = await aiModel.generateContent(prompt)
          result.value = response.response.text()
        }

        console.log('üì® Response received!')
        return result.value
      }

      await withRetry(generateFn, onRetryCallback)
      console.log('‚úÖ Result set:', result.value.substring(0, 100))
    } catch (err) {
      console.error('üí• Error in useGemini:', err)
      error.value = err instanceof Error ? err.message : 'Erreur lors de la g√©n√©ration'
      throw err
    } finally {
      loading.value = false
      isStreaming.value = false
      retryCount.value = 0
      console.log('üèÅ Loading set to false')
    }
  }

  const analyzeResource = async (apiKey: string, url: string, title: string) => {
    loading.value = true
    error.value = ''

    try {
      const genAI = new GoogleGenerativeAI(apiKey)
      const model = genAI.getGenerativeModel({ model: 'gemini-3-flash-preview' })

      const prompt = `Analyse cette ressource p√©dagogique :
Titre: ${title}
URL: ${url}

R√©ponds avec ce JSON exact :
{
  "duration": "dur√©e estim√©e (ex: 10 min, 1h30)",
  "tags": ["tag1", "tag2", "tag3"],
  "summary": "r√©sum√© en 1-2 phrases"
}`

      const response = await model.generateContent(prompt)
      const text = response.response.text()

      // Extract JSON from markdown code blocks if present
      const jsonMatch = text.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0])
      }

      return JSON.parse(text)
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'Erreur lors de l\'analyse'
      return null
    } finally {
      loading.value = false
    }
  }

  const generateSearchTerms = async (apiKey: string, outcome: LearningOutcome) => {
    loading.value = true
    error.value = ''

    try {
      const fn = async () => {
        const genAI = new GoogleGenerativeAI(apiKey)
        const model = genAI.getGenerativeModel({
          model: 'gemini-3-flash-preview',
          generationConfig: { responseMimeType: 'application/json' }
        })

        const context = outcome.description
        const prompt = `Agis comme un expert p√©dagogique.
Sujet : "${context}" (Niveau ${outcome.level}).

Ta mission : Cr√©er les meilleures requ√™tes de recherche pour trouver des ressources de qualit√©.

R√©ponds avec ce JSON :
{
  "youtube": ["requ√™te1", "requ√™te2", "requ√™te3"],
  "google": ["requ√™te1", "requ√™te2", "requ√™te3"],
  "wikipedia": ["terme1", "terme2"]
}

Consignes :
- YouTube : tutoriels vid√©os concrets
- Google : articles, guides, PDFs
- Wikipedia : concepts th√©oriques

Sois sp√©cifique et pertinent.`

        const response = await model.generateContent(prompt)
        const text = response.response.text()
        return JSON.parse(text)
      }

      return await withRetry(fn)
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'Erreur lors de la g√©n√©ration'
      return null
    } finally {
      loading.value = false
    }
  }

  const analyzeSyllabus = async (apiKey: string, content: string, allOutcomes: LearningOutcome[]) => {
    loading.value = true
    error.value = ''

    try {
      const genAI = new GoogleGenerativeAI(apiKey)
      const model = genAI.getGenerativeModel({
        model: 'gemini-2.5-pro',
        generationConfig: { responseMimeType: 'application/json' }
      })

      const outcomesText = allOutcomes.map(o => `${o.id}: ${o.description}`).join('\n')

      const prompt = `Analyse ce syllabus de cours et identifie les comp√©tences DigComp correspondantes.

**Syllabus:**
${content.substring(0, 10000)}

**Comp√©tences DigComp disponibles:**
${outcomesText}

R√©ponds avec ce JSON :
{
  "matches": [
    {
      "outcomeId": "ID exact de la comp√©tence",
      "confidence": "score de 0 √† 100",
      "reasoning": "justification courte"
    }
  ]
}

S√©lectionne 3 √† 8 comp√©tences les plus pertinentes.`

      const response = await model.generateContent(prompt)
      const text = response.response.text()
      return JSON.parse(text)
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'Erreur lors de l\'analyse'
      return null
    } finally {
      loading.value = false
    }
  }

  // Magic import: analyze URL and find matching LOs
  const analyzeUrl = async (
    apiKey: string,
    url: string,
    allOutcomes: LearningOutcome[]
  ): Promise<MagicImportResult | null> => {
    loading.value = true
    error.value = ''

    try {
      const fn = async () => {
        const genAI = new GoogleGenerativeAI(apiKey)
        const model = genAI.getGenerativeModel({
          model: 'gemini-2.5-pro',
          generationConfig: { responseMimeType: 'application/json' }
        })

        const outcomesText = allOutcomes.slice(0, 100).map(o => `${o.id}: ${o.description}`).join('\n')

        const prompt = `Analyse cette URL de ressource p√©dagogique et identifie les comp√©tences DigComp qu'elle pourrait d√©velopper.

**URL √† analyser:** ${url}

**Comp√©tences DigComp disponibles:**
${outcomesText}

R√©ponds avec ce JSON :
{
  "title": "Titre de la ressource d√©duit de l'URL",
  "summary": "Description de ce que contient cette ressource (1-2 phrases)",
  "suggestedType": "video" ou "document" ou "file",
  "matches": [
    {
      "outcomeId": "ID exact de la comp√©tence (ex: LO1.1.01)",
      "confidence": 85,
      "reasoning": "Pourquoi cette ressource correspond √† cette comp√©tence"
    }
  ]
}

Instructions :
- D√©duis le contenu probable de l'URL (YouTube, article, PDF, etc.)
- S√©lectionne 1 √† 5 comp√©tences les plus pertinentes
- Donne un score de confiance r√©aliste (0-100)
- Le type sugg√©r√© d√©pend de l'URL (youtube = video, article = document, etc.)`

        const response = await model.generateContent(prompt)
        const text = response.response.text()
        const parsed = JSON.parse(text)

        return {
          url,
          title: parsed.title || 'Ressource import√©e',
          summary: parsed.summary || '',
          matches: parsed.matches || [],
          suggestedType: parsed.suggestedType || 'document'
        } as MagicImportResult
      }

      return await withRetry(fn)
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'Erreur lors de l\'analyse'
      return null
    } finally {
      loading.value = false
    }
  }

  const chatWithData = async (apiKey: string, question: string, digcompData: any) => {
    loading.value = true
    error.value = ''
    result.value = ''

    try {
      const genAI = new GoogleGenerativeAI(apiKey)
      const model = genAI.getGenerativeModel({ model: 'gemini-2.5-pro' })

      // Simplify data to reduce tokens
      const simplifiedData = {
        totalDomains: digcompData.domains?.length || 0,
        domains: digcompData.domains?.map((d: any) => ({
          id: d.id,
          name: d.name,
          competences: d.competences?.map((c: any) => ({
            id: c.id,
            name: c.name,
            outcomes: c.outcomes?.map((o: any) => ({
              id: o.id,
              level: o.level,
              statusL1: o.mappings?.L1?.status,
              statusL2: o.mappings?.L2?.status,
              statusL3: o.mappings?.L3?.status,
              hasResourcesL1: (o.mappings?.L1?.resources?.length || 0) > 0,
              hasResourcesL2: (o.mappings?.L2?.resources?.length || 0) > 0,
              hasResourcesL3: (o.mappings?.L3?.resources?.length || 0) > 0
            }))
          }))
        }))
      }

      const prompt = `Tu es un assistant sp√©cialis√© dans l'analyse du r√©f√©rentiel DigComp.

Donn√©es du r√©f√©rentiel :
${JSON.stringify(simplifiedData, null, 2)}

Question de l'utilisateur : ${question}

R√©ponds de mani√®re claire et concise en fran√ßais. Utilise des statistiques pr√©cises si pertinent.`

      const response = await model.generateContent(prompt)
      result.value = response.response.text()
      return result.value
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'Erreur lors de la requ√™te'
      throw err
    } finally {
      loading.value = false
    }
  }

  return {
    loading,
    result,
    error,
    streamingText,
    isStreaming,
    retryCount,
    validateApiKey,
    generateContent,
    analyzeResource,
    generateSearchTerms,
    analyzeSyllabus,
    analyzeUrl,
    chatWithData
  }
}
